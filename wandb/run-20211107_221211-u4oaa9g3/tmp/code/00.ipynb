{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f258937-4fd2-4bc0-b7ad-0b0b2575de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch,torchvision\n",
    "import random\n",
    "from tqdm import *\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "stemmer = PorterStemmer()\n",
    "PROJECT_NAME = 'NLP-with-Disaster-Tweets-cleaning-data-V3'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e2a607-d64b-4525-b791-357471b160ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5de66a0-118e-4924-beae-173819d25902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', '100']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"@100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357cf9a4-307e-42a1-a134-de31d0149c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81792caa-33b9-4deb-8cef-4edba23f1aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem('organic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c257ee94-c48f-46ac-b04c-385baab7eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_words,words):\n",
    "    tokenized_words = [stem(w) for w in tokenized_words]\n",
    "    bag = np.zeros(len(words))\n",
    "    for idx,w in enumerate(words):\n",
    "        if w in tokenized_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63fc6a25-6fb1-4692-939e-7922ec656089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(['hi'],['hi','how','hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1626f544-0e68-44f5-b89f-6079d257d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv').sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45110c7-4e35-481b-ba38-eccd9515986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ecf22c4-0034-41a0-ba1a-7f9484ba00b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>2846</td>\n",
       "      <td>cyclone</td>\n",
       "      <td>Geneva</td>\n",
       "      <td>Blending the old with the new in  # Vanuatu to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>2587</td>\n",
       "      <td>crash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>? One night and we are gonna come and crash t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>4041</td>\n",
       "      <td>disaster</td>\n",
       "      <td>Calgary, AB</td>\n",
       "      <td>The  @ rbcinsurance quote website  =  disaster...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521</th>\n",
       "      <td>9325</td>\n",
       "      <td>survive</td>\n",
       "      <td>? icon by @Hashiren_3 ?</td>\n",
       "      <td>@ mochichiiiii  @ hikagezero IT ' S IMPOSSIBL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>3410</td>\n",
       "      <td>derail</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>@ BV Bloomberg will publish anything negative...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016</th>\n",
       "      <td>8591</td>\n",
       "      <td>screams</td>\n",
       "      <td>texas</td>\n",
       "      <td>SCREAMS AT MY OWN MOTHER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>8580</td>\n",
       "      <td>screams</td>\n",
       "      <td>lost in history</td>\n",
       "      <td>SCREAMS .  WHERE IS EVERYONE . \\n\\noh wait sch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>9832</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>@ thetimepast  @ saalon I have childhood trau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>4706</td>\n",
       "      <td>epicentre</td>\n",
       "      <td>Africa</td>\n",
       "      <td>RT  @ calestous :  Tanzania elephant populatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>332</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>PA</td>\n",
       "      <td>Officially skipping out on  # Fantastic Four /...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword                 location  \\\n",
       "1978  2846      cyclone                   Geneva   \n",
       "1800  2587        crash                      NaN   \n",
       "2809  4041     disaster              Calgary, AB   \n",
       "6521  9325      survive  ? icon by @Hashiren_3 ?   \n",
       "2371  3410       derail          Los Angeles, CA   \n",
       "...    ...          ...                      ...   \n",
       "6016  8591      screams                    texas   \n",
       "6008  8580      screams          lost in history   \n",
       "6860  9832       trauma          Little Rock, AR   \n",
       "3280  4706    epicentre                   Africa   \n",
       "233    332  annihilated                       PA   \n",
       "\n",
       "                                                   text  target  \n",
       "1978  Blending the old with the new in  # Vanuatu to...       0  \n",
       "1800   ? One night and we are gonna come and crash t...       0  \n",
       "2809  The  @ rbcinsurance quote website  =  disaster...       0  \n",
       "6521   @ mochichiiiii  @ hikagezero IT ' S IMPOSSIBL...       0  \n",
       "2371   @ BV Bloomberg will publish anything negative...       0  \n",
       "...                                                 ...     ...  \n",
       "6016                          SCREAMS AT MY OWN MOTHER        0  \n",
       "6008  SCREAMS .  WHERE IS EVERYONE . \\n\\noh wait sch...       0  \n",
       "6860   @ thetimepast  @ saalon I have childhood trau...       0  \n",
       "3280  RT  @ calestous :  Tanzania elephant populatio...       1  \n",
       "233   Officially skipping out on  # Fantastic Four /...       0  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ef6ace-560e-4467-a943-5db498b5b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b6af612-0e76-415a-8969-0b72a1b4f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "data = []\n",
    "labels = {}\n",
    "labels_r = {}\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7663c08f-45aa-4290-99c3-8a4918f79e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in y.tolist():\n",
    "    if label not in list(labels.keys()):\n",
    "        idx += 1\n",
    "        labels[label] = idx\n",
    "        labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2335156f-8311-4ec7-871c-24b4e31101e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b309ae-fc41-4cfb-8446-b1e20339b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7613it [00:02, 3243.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for X_batch,y_batch in tqdm(zip(X,y)):\n",
    "    X_batch = tokenize(X_batch)\n",
    "    new_X = []\n",
    "    for Xb in X_batch:\n",
    "        new_X.append(stem(Xb))\n",
    "    words.extend(new_X)\n",
    "    data.append([\n",
    "        new_X,\n",
    "        np.eye(labels[y_batch],len(labels))[labels[y_batch]-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f317049-3c72-4851-8bd9-f1bca16a3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2fee212-a75f-466c-bb53-029132e0bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c5d0ba-a5c1-4630-86f1-144611759e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccaf8808-0584-4a24-91c3-fd4fd6c3c1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7613/7613 [00:21<00:00, 350.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for sentence,tag in tqdm(data):\n",
    "    X.append(bag_of_words(sentence,words))\n",
    "    y.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b694e599-a950-44e7-9e47-627159f3c090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c07733b3-cee2-47e2-b3f3-d4f1ee0c0e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26f92e0e-a65f-4879-8f28-e9b77023a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import *\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.125,shuffle=False)\n",
    "X_train = torch.from_numpy(np.array(X_train)).to(device).float()\n",
    "y_train = torch.from_numpy(np.array(y_train)).to(device).float()\n",
    "X_test = torch.from_numpy(np.array(X_test)).to(device).float()\n",
    "y_test = torch.from_numpy(np.array(y_test)).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f37601b-6584-4009-9816-50b8e75bd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52b7cc9e-f121-4df2-aab0-3b62101ebcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,yb in zip(preds,y):\n",
    "        pred = int(torch.argmax(pred))\n",
    "        yb = int(torch.argmax(yb))\n",
    "        if pred == yb:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a44c6e1a-75ab-422d-b994-76ec56308224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 1024\n",
    "        self.activation = ReLU()\n",
    "        self.linear1 = Linear(len(words),self.hidden)\n",
    "        self.linear2 = Linear(self.hidden,self.hidden)\n",
    "        self.linear3 = Linear(self.hidden,len(labels))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.linear1(X)\n",
    "        preds = self.linear2(preds)\n",
    "        preds = self.activation(preds)\n",
    "        preds = self.linear3(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f03d9a05-9480-472e-b53a-2f30a17c64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5b239-9cba-45b7-ada3-7b87675c9476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/NLP-with-Disaster-Tweets-cleaning-data-V3/runs/u4oaa9g3\" target=\"_blank\">baseline</a></strong> to <a href=\"https://wandb.ai/ranuga-d/NLP-with-Disaster-Tweets-cleaning-data-V3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [01:28<01:10,  1.65s/it]"
     ]
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion)/2)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Acc':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a62f4-d9d4-48a4-9422-9a940ab97c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'model.pt')\n",
    "torch.save(model,'model.pth')\n",
    "torch.save(model.state_dict(),'model-sd.pt')\n",
    "torch.save(model.state_dict(),'model-sd.pth')\n",
    "torch.save(X,'X.pt')\n",
    "torch.save(X,'X.pth')\n",
    "torch.save(y,'y.pt')\n",
    "torch.save(y,'y.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d806e-87b4-476f-8352-fda42aa9b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_train,'X_train.pt')\n",
    "torch.save(X_test,'X_test.pth')\n",
    "torch.save(y_train,'y_train.pt')\n",
    "torch.save(y_test,'y_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8dd65-c604-460e-bbec-33126be7e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(words,'words.pt')\n",
    "torch.save(words,'words.pth')\n",
    "torch.save(data,'data.pt')\n",
    "torch.save(data,'data.pth')\n",
    "torch.save(labels,'labels.pt')\n",
    "torch.save(labels,'labels.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e89514-add7-4b76-86cb-6ddfa19c1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(idx,'idx.pt')\n",
    "torch.save(idx,'idx.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270558e-e992-4160-8dc0-f63ad9932812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd07338908a6901250255932625ba4b5c32a9d91564d69b39dc5095100e5c96b0b4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
