{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f258937-4fd2-4bc0-b7ad-0b0b2575de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch,torchvision\n",
    "import random\n",
    "from tqdm import *\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "stemmer = PorterStemmer()\n",
    "PROJECT_NAME = 'NLP-with-Disaster-Tweets-cleaning-data-V3'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e2a607-d64b-4525-b791-357471b160ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5de66a0-118e-4924-beae-173819d25902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', '100']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"@100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357cf9a4-307e-42a1-a134-de31d0149c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81792caa-33b9-4deb-8cef-4edba23f1aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem('organic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c257ee94-c48f-46ac-b04c-385baab7eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_words,words):\n",
    "    tokenized_words = [stem(w) for w in tokenized_words]\n",
    "    bag = np.zeros(len(words))\n",
    "    for idx,w in enumerate(words):\n",
    "        if w in tokenized_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63fc6a25-6fb1-4692-939e-7922ec656089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(['hi'],['hi','how','hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1626f544-0e68-44f5-b89f-6079d257d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')[:3250].sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f45110c7-4e35-481b-ba38-eccd9515986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ecf22c4-0034-41a0-ba1a-7f9484ba00b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>3286</td>\n",
       "      <td>demolish</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>The far right racist  # AvigdorLiberman calls ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>4425</td>\n",
       "      <td>electrocute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>She says that she ' d love to come help but\\nT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2097</td>\n",
       "      <td>casualty</td>\n",
       "      <td>In @4SkinChan 's arms</td>\n",
       "      <td>@ reriellechan HE WAS THE LICH KING ' S FIRST...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>2443</td>\n",
       "      <td>collide</td>\n",
       "      <td>Medford, NJ</td>\n",
       "      <td># TheDoolingGroup 2 injured when 2 school bus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>1335</td>\n",
       "      <td>blown%20up</td>\n",
       "      <td>801 SL,UT</td>\n",
       "      <td>Damn greinke got blown up in that first inning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1943</td>\n",
       "      <td>burning%20buildings</td>\n",
       "      <td>New Orleans ,Louisiana</td>\n",
       "      <td>Burning buildings ?  Media outrage ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>3690</td>\n",
       "      <td>destroy</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Politics  =  Preschool Attitude :  Russia orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>2204</td>\n",
       "      <td>catastrophic</td>\n",
       "      <td>Lurking</td>\n",
       "      <td>Pretty much every time the audio dies on an au...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>1005</td>\n",
       "      <td>blazing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I am blazing rn and there is nothing you can d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1693</td>\n",
       "      <td>bridge%20collapse</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3250 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id              keyword                location  \\\n",
       "2291  3286             demolish              London, UK   \n",
       "3083  4425          electrocute                     NaN   \n",
       "1454  2097             casualty   In @4SkinChan 's arms   \n",
       "1693  2443              collide             Medford, NJ   \n",
       "922   1335           blown%20up               801 SL,UT   \n",
       "...    ...                  ...                     ...   \n",
       "1345  1943  burning%20buildings  New Orleans ,Louisiana   \n",
       "2573  3690              destroy                  Norway   \n",
       "1524  2204         catastrophic                 Lurking   \n",
       "698   1005              blazing                     NaN   \n",
       "1176  1693    bridge%20collapse                  Boston   \n",
       "\n",
       "                                                   text  target  \n",
       "2291  The far right racist  # AvigdorLiberman calls ...       1  \n",
       "3083  She says that she ' d love to come help but\\nT...       0  \n",
       "1454   @ reriellechan HE WAS THE LICH KING ' S FIRST...       1  \n",
       "1693   # TheDoolingGroup 2 injured when 2 school bus...       1  \n",
       "922      Damn greinke got blown up in that first inning       0  \n",
       "...                                                 ...     ...  \n",
       "1345             Burning buildings ?  Media outrage ?         1  \n",
       "2573  Politics  =  Preschool Attitude :  Russia orde...       1  \n",
       "1524  Pretty much every time the audio dies on an au...       0  \n",
       "698   I am blazing rn and there is nothing you can d...       0  \n",
       "1176  Two giant cranes holding a bridge collapse int...       1  \n",
       "\n",
       "[3250 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04ef6ace-560e-4467-a943-5db498b5b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b6af612-0e76-415a-8969-0b72a1b4f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "data = []\n",
    "labels = {}\n",
    "labels_r = {}\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7663c08f-45aa-4290-99c3-8a4918f79e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in y.tolist():\n",
    "    if label not in list(labels.keys()):\n",
    "        idx += 1\n",
    "        labels[label] = idx\n",
    "        labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2335156f-8311-4ec7-871c-24b4e31101e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1, 0: 2}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9b309ae-fc41-4cfb-8446-b1e20339b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3250it [00:00, 3272.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for X_batch,y_batch in tqdm(zip(X,y)):\n",
    "    X_batch = tokenize(X_batch)\n",
    "    new_X = []\n",
    "    for Xb in X_batch:\n",
    "        new_X.append(stem(Xb))\n",
    "    words.extend(new_X)\n",
    "    data.append([\n",
    "        new_X,\n",
    "        np.eye(labels[y_batch],len(labels))[labels[y_batch]-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f317049-3c72-4851-8bd9-f1bca16a3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2fee212-a75f-466c-bb53-029132e0bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9c5d0ba-a5c1-4630-86f1-144611759e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccaf8808-0584-4a24-91c3-fd4fd6c3c1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3250/3250 [00:05<00:00, 609.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for sentence,tag in tqdm(data):\n",
    "    X.append(bag_of_words(sentence,words))\n",
    "    y.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b694e599-a950-44e7-9e47-627159f3c090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c07733b3-cee2-47e2-b3f3-d4f1ee0c0e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26f92e0e-a65f-4879-8f28-e9b77023a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import *\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.125,shuffle=False)\n",
    "X_train = torch.from_numpy(np.array(X_train)).to(device).float()\n",
    "y_train = torch.from_numpy(np.array(y_train)).to(device).float()\n",
    "X_test = torch.from_numpy(np.array(X_test)).to(device).float()\n",
    "y_test = torch.from_numpy(np.array(y_test)).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f37601b-6584-4009-9816-50b8e75bd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7cc9e-f121-4df2-aab0-3b62101ebcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,yb in zip(preds,y):\n",
    "        pred = int(torch.argmax(pred))\n",
    "        yb = int(torch.argmax(yb))\n",
    "        if pred == yb:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c6e1a-75ab-422d-b994-76ec56308224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 512\n",
    "        self.activation = ReLU()\n",
    "        self.linear1 = Linear(len(words),self.hidden)\n",
    "        self.linear2 = Linear(self.hidden,self.hidden)\n",
    "        self.linear3 = Linear(self.hidden,len(labels))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.linear1(X)\n",
    "        preds = self.activation(self.linear2(preds))\n",
    "        preds = self.linear3(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d9a05-9480-472e-b53a-2f30a17c64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5b239-9cba-45b7-ada3-7b87675c9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion)/2)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Acc':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a62f4-d9d4-48a4-9422-9a940ab97c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'model.pt')\n",
    "torch.save(model,'model.pth')\n",
    "torch.save(model.state_dict(),'model-sd.pt')\n",
    "torch.save(model.state_dict(),'model-sd.pth')\n",
    "torch.save(X,'X.pt')\n",
    "torch.save(X,'X.pth')\n",
    "torch.save(y,'y.pt')\n",
    "torch.save(y,'y.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d806e-87b4-476f-8352-fda42aa9b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_train,'X_train.pt')\n",
    "torch.save(X_test,'X_test.pth')\n",
    "torch.save(y_train,'y_train.pt')\n",
    "torch.save(y_test,'y_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8dd65-c604-460e-bbec-33126be7e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(words,'words.pt')\n",
    "torch.save(words,'words.pth')\n",
    "torch.save(data,'data.pt')\n",
    "torch.save(data,'data.pth')\n",
    "torch.save(labels,'labels.pt')\n",
    "torch.save(labels,'labels.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e89514-add7-4b76-86cb-6ddfa19c1fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd07338908a6901250255932625ba4b5c32a9d91564d69b39dc5095100e5c96b0b4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
