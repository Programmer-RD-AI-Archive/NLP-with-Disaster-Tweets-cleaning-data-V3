{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5812b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch,torchvision\n",
    "import random\n",
    "from tqdm import *\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "stemmer = PorterStemmer()\n",
    "PROJECT_NAME = 'NLP-with-Disaster-Tweets-cleaning-data-V3'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facf0857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7427a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', '100']"
     ]
    }
   ],
   "source": [
    "tokenize(\"@100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd15b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465d44da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'organ'"
     ]
    }
   ],
   "source": [
    "stem('organic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88dbe7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_words,words):\n",
    "    tokenized_words = [stem(w) for w in tokenized_words]\n",
    "    bag = np.zeros(len(words))\n",
    "    for idx,w in enumeraten(words):\n",
    "        if w in tokenized_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "085e288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words(['hi'],['hi','how','hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac47d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_words,words):\n",
    "    tokenized_words = [stem(w) for w in tokenized_words]\n",
    "    bag = np.zeros(len(words))\n",
    "    for idx,w in enumerate(words):\n",
    "        if w in tokenized_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a7f86ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1., 0., 1.])"
     ]
    }
   ],
   "source": [
    "bag_of_words(['hi'],['hi','how','hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fe7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3265f03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this  # earthquake...       1  \n",
      "1              Forest fire near La Ronge Sask .  Canada       1  \n",
      "2     All residents asked to  ' shelter in place '  ...       1  \n",
      "3     13,000 people receive  # wildfires evacuation ...       1  \n",
      "4     Just got sent this photo from Ruby  # Alaska a...       1  \n",
      "...                                                 ...     ...  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609   @ Aria Ahrary  @ TheTawniest The out of contr...       1  \n",
      "7610  M1 . 94  [ 01 : 04 UTC ]  ? 5km S of Volcano H...       1  \n",
      "7611  Police investigating after an e - bike collide...       1  \n",
      "7612  The Latest :  More Homes Razed by Northern Cal...       1  \n",
      "\n",
      "[7613 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0e9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44bb91c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this  # earthquake...       1  \n",
      "1              Forest fire near La Ronge Sask .  Canada       1  \n",
      "2     All residents asked to  ' shelter in place '  ...       1  \n",
      "3     13,000 people receive  # wildfires evacuation ...       1  \n",
      "4     Just got sent this photo from Ruby  # Alaska a...       1  \n",
      "...                                                 ...     ...  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609   @ Aria Ahrary  @ TheTawniest The out of contr...       1  \n",
      "7610  M1 . 94  [ 01 : 04 UTC ]  ? 5km S of Volcano H...       1  \n",
      "7611  Police investigating after an e - bike collide...       1  \n",
      "7612  The Latest :  More Homes Razed by Northern Cal...       1  \n",
      "\n",
      "[7613 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c64500d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e14926ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "data = []\n",
    "labels = {}\n",
    "labels_r = {}\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9138b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in y.tolist():\n",
    "    if label not in list(labels.keys()):\n",
    "        idx += 1\n",
    "        labels[label] = idx\n",
    "        labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a5b92eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 0: 2}"
     ]
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a34e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')[:3250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "919a56b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3e56d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id   keyword          location  \\\n",
      "0        1       NaN               NaN   \n",
      "1        4       NaN               NaN   \n",
      "2        5       NaN               NaN   \n",
      "3        6       NaN               NaN   \n",
      "4        7       NaN               NaN   \n",
      "...    ...       ...               ...   \n",
      "3245  4664  engulfed  Fleet/Oxford, UK   \n",
      "3246  4666  engulfed               NaN   \n",
      "3247  4667  engulfed                UK   \n",
      "3248  4669  engulfed           Bahrain   \n",
      "3249  4670  engulfed          Coventry   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this  # earthquake...       1  \n",
      "1              Forest fire near La Ronge Sask .  Canada       1  \n",
      "2     All residents asked to  ' shelter in place '  ...       1  \n",
      "3     13,000 people receive  # wildfires evacuation ...       1  \n",
      "4     Just got sent this photo from Ruby  # Alaska a...       1  \n",
      "...                                                 ...     ...  \n",
      "3245  just got engulfed in a car - induced tidal wav...       0  \n",
      "3246   @ FNAF_TalkMC  * stands there engulfed in the...       0  \n",
      "3247  Tube strike live :  Latest travel updates as L...       1  \n",
      "3248  He came to a land which was engulfed in tribal...       1  \n",
      "3249  Do you feel engulfed with low self - image ?  ...       0  \n",
      "\n",
      "[3250 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f1f5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e06e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "data = []\n",
    "labels = {}\n",
    "labels_r = {}\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8e465b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in y.tolist():\n",
    "    if label not in list(labels.keys()):\n",
    "        idx += 1\n",
    "        labels[label] = idx\n",
    "        labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14e98245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 0: 2}"
     ]
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f38d2fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')[:3250].sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23f87502",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74bae3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id              keyword                location  \\\n",
      "2291  3286             demolish              London, UK   \n",
      "3083  4425          electrocute                     NaN   \n",
      "1454  2097             casualty   In @4SkinChan 's arms   \n",
      "1693  2443              collide             Medford, NJ   \n",
      "922   1335           blown%20up               801 SL,UT   \n",
      "...    ...                  ...                     ...   \n",
      "1345  1943  burning%20buildings  New Orleans ,Louisiana   \n",
      "2573  3690              destroy                  Norway   \n",
      "1524  2204         catastrophic                 Lurking   \n",
      "698   1005              blazing                     NaN   \n",
      "1176  1693    bridge%20collapse                  Boston   \n",
      "\n",
      "                                                   text  target  \n",
      "2291  The far right racist  # AvigdorLiberman calls ...       1  \n",
      "3083  She says that she ' d love to come help but\\nT...       0  \n",
      "1454   @ reriellechan HE WAS THE LICH KING ' S FIRST...       1  \n",
      "1693   # TheDoolingGroup 2 injured when 2 school bus...       1  \n",
      "922      Damn greinke got blown up in that first inning       0  \n",
      "...                                                 ...     ...  \n",
      "1345             Burning buildings ?  Media outrage ?         1  \n",
      "2573  Politics  =  Preschool Attitude :  Russia orde...       1  \n",
      "1524  Pretty much every time the audio dies on an au...       0  \n",
      "698   I am blazing rn and there is nothing you can d...       0  \n",
      "1176  Two giant cranes holding a bridge collapse int...       1  \n",
      "\n",
      "[3250 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1b7c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "171bca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "data = []\n",
    "labels = {}\n",
    "labels_r = {}\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb890331",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in y.tolist():\n",
    "    if label not in list(labels.keys()):\n",
    "        idx += 1\n",
    "        labels[label] = idx\n",
    "        labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d43600af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 0: 2}"
     ]
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "268f9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch,y_batch in tqdm(zip(X,y)):\n",
    "    X_batch = tokenize(X_batch)\n",
    "    new_Xb = []\n",
    "    for Xb in X_batch:\n",
    "        new_Xb.append(stem(Xb))\n",
    "    words.extend(new_X)\n",
    "    data.append([\n",
    "        new_X,\n",
    "        np.eye(labels[y_batch],len(labels))[labels[y_batch]-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba35cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch,y_batch in tqdm(zip(X,y)):\n",
    "    X_batch = tokenize(X_batch)\n",
    "    new_X = []\n",
    "    for Xb in X_batch:\n",
    "        new_X.append(stem(Xb))\n",
    "    words.extend(new_X)\n",
    "    data.append([\n",
    "        new_X,\n",
    "        np.eye(labels[y_batch],len(labels))[labels[y_batch]-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee7f7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the',\n",
      "  'far',\n",
      "  'right',\n",
      "  'racist',\n",
      "  '#',\n",
      "  'avigdorliberman',\n",
      "  'call',\n",
      "  'for',\n",
      "  'destruct',\n",
      "  'of',\n",
      "  '#',\n",
      "  'susiya',\n",
      "  '!',\n",
      "  'previous',\n",
      "  'he',\n",
      "  'also',\n",
      "  'call',\n",
      "  'for',\n",
      "  'behead',\n",
      "  '!'],\n",
      " array([1., 0.])]"
     ]
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5630e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['@',\n",
      "  'cllrraymogford',\n",
      "  'inde',\n",
      "  'ray',\n",
      "  'devast',\n",
      "  'would',\n",
      "  'be',\n",
      "  'far',\n",
      "  'more',\n",
      "  'comprehens',\n",
      "  '#',\n",
      "  'hiroshima'],\n",
      " array([1., 0.])]"
     ]
    }
   ],
   "source": [
    "data[650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c61931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['youth', 'electrocut', 'in', 'khulna', '|', 'via', '@', 'sharethi'],\n",
      " array([1., 0.])]"
     ]
    }
   ],
   "source": [
    "data[654]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfd5dcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['youth', 'electrocut', 'in', 'khulna', '|', 'via', '@', 'sharethi'],\n",
      " array([1., 0.])]"
     ]
    }
   ],
   "source": [
    "data[654]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93c3105e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['/',\n",
      "  '/',\n",
      "  'im',\n",
      "  'gon',\n",
      "  'na',\n",
      "  'beat',\n",
      "  'armageddon',\n",
      "  'as',\n",
      "  'hsu',\n",
      "  'hao',\n",
      "  '?',\n",
      "  'just',\n",
      "  'got',\n",
      "  'a',\n",
      "  'flawless',\n",
      "  'on',\n",
      "  'my',\n",
      "  'first',\n",
      "  'tri'],\n",
      " array([0., 1.])]"
     ]
    }
   ],
   "source": [
    "data[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81bfea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbfbd894",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a4e3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e15440e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence,tag in tqdm(data):\n",
    "    X.append(bag_of_words(sentence,words))\n",
    "    y.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e81b304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 0., 0., ..., 0., 0., 0.])"
     ]
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b364e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 1.])"
     ]
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "802776d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 0., 0., ..., 0., 0., 0.])"
     ]
    }
   ],
   "source": [
    "X[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a8e6c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 0., 0., ..., 0., 0., 0.])"
     ]
    }
   ],
   "source": [
    "X[590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4240832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0"
     ]
    }
   ],
   "source": [
    "X[590][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7665d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0"
     ]
    }
   ],
   "source": [
    "X[590][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d3152cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 0., 0., ..., 0., 0., 0.])"
     ]
    }
   ],
   "source": [
    "X[590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cf7ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[590])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "993059e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in X[590]:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aeaf0b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@',\n",
      " 'kshllcenterpri1',\n",
      " '@',\n",
      " 'progress4ohio',\n",
      " 'burn',\n",
      " 'down',\n",
      " 'build',\n",
      " 'what',\n",
      " 'you',\n",
      " 'mean',\n",
      " 'like',\n",
      " 'when',\n",
      " 'you',\n",
      " 'burnt',\n",
      " 'down',\n",
      " 'those',\n",
      " 'black',\n",
      " 'church',\n",
      " '?']"
     ]
    }
   ],
   "source": [
    "data[590][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a2c6a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 0., 0., ..., 0., 0., 0.])"
     ]
    }
   ],
   "source": [
    "X[590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce0559fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 1.])"
     ]
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13084e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import *\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.125,shuffle=False)\n",
    "X_train = torch.from_numpy(np.array(X_train)).to(device).float()\n",
    "y_train = torch.from_numpy(np.array(y_train)).to(device).float()\n",
    "X_test = torch.from_numpy(np.array(X_test)).to(device).float()\n",
    "y_test = torch.from_numpy(np.array(y_test)).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "604afba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f824adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,yb in zip(preds,y):\n",
    "        pred = int(torch.argmax(pred))\n",
    "        yb = int(torch.argmax(yb))\n",
    "        if pred == yb:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd9507ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 512\n",
    "        self.activation = ReLU()\n",
    "        self.linear1 = Linear(len(words),self.hidden)\n",
    "        self.linear2 = Linear(self.hidden,self.hidden)\n",
    "        self.linear3 = Linear(self.hidden,len(labels))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.linear1(X)\n",
    "        preds = self.activation(self.linear2(preds))\n",
    "        preds = self.linear3(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e74133f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "126229b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/NLP-with-Disaster-Tweets-cleaning-data-V3/runs/2ojtps92\" target=\"_blank\">baseline</a></strong> to <a href=\"https://wandb.ai/ranuga-d/NLP-with-Disaster-Tweets-cleaning-data-V3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion)/2)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Acc':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af9abe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,yb in zip(preds,y):\n",
    "        pred = int(torch.argmax(pred))\n",
    "        yb = int(torch.argmax(yb))\n",
    "        if pred == yb:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd32dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 512\n",
    "        self.activation = ReLU()\n",
    "        self.linear1 = Linear(len(words),self.hidden)\n",
    "        self.linear2 = Linear(self.hidden,self.hidden)\n",
    "        self.linear3 = Linear(self.hidden,len(labels))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.linear1(X)\n",
    "        preds = self.activation(self.linear2(preds))\n",
    "        preds = self.linear3(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0abe2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6b4307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion)/2)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Acc':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
